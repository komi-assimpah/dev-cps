# ====================================================================
# DOCKER COMPOSE - Environnement de dÃ©veloppement avec Kafka
# ====================================================================
# Ce fichier configure 3 services :
# 1. MongoDB : Base de donnÃ©es NoSQL pour stocker des donnÃ©es
# 2. Kafka : Plateforme de streaming de messages en temps rÃ©el
# 3. Kafka-UI : Interface web pour visualiser et gÃ©rer Kafka
# ====================================================================
#
# ğŸ“š CONCEPTS IMPORTANTS POUR DÃ‰BUTANTS
# ====================================================================
#
# ğŸŒ QU'EST-CE QU'UN CLUSTER ?
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Un CLUSTER = groupe de plusieurs serveurs qui travaillent ensemble.
#
# Votre configuration actuelle (dÃ©veloppement) :
#     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#     â”‚  Kafka Broker 1 â”‚  â† 1 seul serveur (suffit pour apprendre)
#     â”‚  (Node ID: 1)   â”‚
#     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# Configuration production (3 brokers en cluster) :
#     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#     â”‚ Broker1 â”‚   â”‚ Broker2 â”‚   â”‚ Broker3 â”‚
#     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
#          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#              Cluster Kafka
#
# Avantages du cluster :
#   âœ“ Haute disponibilitÃ© (si 1 tombe, les autres continuent)
#   âœ“ Performance (charge rÃ©partie)
#   âœ“ RÃ©silience (donnÃ©es rÃ©pliquÃ©es)
#
# ğŸ˜ QU'EST-CE QUE ZOOKEEPER ?
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Zookeeper Ã©tait l'ANCIEN systÃ¨me de coordination de Kafka.
# Il jouait le rÃ´le de "chef d'orchestre".
#
# Ancienne architecture (avec Zookeeper) :
#     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#     â”‚  Zookeeper  â”‚ â† Coordinateur externe
#     â”‚   :2181     â”‚
#     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
#            â”‚
#       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
#       â†“         â†“
#    â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
#    â”‚Kafkaâ”‚  â”‚Kafkaâ”‚ â† Brokers
#    â”‚  1  â”‚  â”‚  2  â”‚
#    â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜
#
# Nouvelle architecture KRaft (votre config) :
#     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#     â”‚  Kafka avec KRaft   â”‚ â† Tout en un !
#     â”‚  (broker +          â”‚
#     â”‚   controller)       â”‚
#     â”‚                     â”‚
#     â”‚ :9092 â†’ Messages    â”‚
#     â”‚ :9093 â†’ Coordinationâ”‚
#     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# Pourquoi KRaft remplace Zookeeper ?
#   âœ“ Plus simple (1 service au lieu de 2)
#   âœ“ Plus rapide (pas de communication externe)
#   âœ“ Meilleure scalabilitÃ©
#   âœ“ Architecture du futur (Zookeeper sera supprimÃ© dans Kafka 4.0)
#
# Le port 9093 est le CONTROLLER qui remplace Zookeeper.
# Les brokers Kafka s'auto-coordonnent via ce port.
#
# ====================================================================

services:
  # ===========================
  # SERVICE 1 : MongoDB
  # ===========================
  # MongoDB est une base de donnÃ©es NoSQL orientÃ©e documents
  # UtilisÃ©e pour stocker des donnÃ©es de maniÃ¨re flexible
  mongodb:
    image: mongo:7.0                    # Version stable de MongoDB
    container_name: mongodb_edge
    ports:
      - "27017:27017"                   # Port standard MongoDB (host:container)
    volumes:
      - mongodb-data:/data/db           # Persiste les donnÃ©es sur le disque
    networks:
      - dev-cps-network                 # RÃ©seau partagÃ© entre tous les services

  # ===========================
  # SERVICE 2 : Kafka (avec KRaft)
  # ===========================
  # Apache Kafka : Plateforme de streaming distribuÃ©
  # Permet de publier, stocker et traiter des flux de messages en temps rÃ©el
  #
  # Cas d'usage :
  # - Messaging entre microservices
  # - Collecte de logs et mÃ©triques
  # - Event sourcing et CQRS
  # - Traitement de flux de donnÃ©es en temps rÃ©el (IoT, analytics)
  #
  # KRaft Mode : Kafka sans Zookeeper (architecture moderne depuis Kafka 3.3)
  kafka:
    image: confluentinc/cp-kafka:7.5.0  
    container_name: kafka_broker
    ports:
      - "9092:9092"                     # Port CLIENT : pour se connecter depuis votre machine
      - "9093:9093"                     # Port CONTROLLER : coordination interne (remplace Zookeeper)

    environment:
      # --- Configuration de base ---
      KAFKA_NODE_ID: 1                  # ID unique de ce broker (important en cluster multi-nÅ“uds)

      # --- Mode KRaft (sans Zookeeper) ---
      KAFKA_PROCESS_ROLES: broker,ycontroller
      # "broker" = stocke et distribue les messages
      # "controller" = gÃ¨re la coordination du cluster (remplace Zookeeper)
      # Ce nÅ“ud fait les deux rÃ´les en mÃªme temps

      # --- Configuration des listeners (endpoints de connexion) ---
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka:9093
      # PLAINTEXT://kafka:29092    â†’ Pour communication ENTRE conteneurs Docker
      # PLAINTEXT_HOST://:9092     â†’ Pour connexion depuis votre MACHINE (localhost)
      # CONTROLLER://kafka:9093    â†’ Pour coordination interne KRaft

      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      # Adresses que Kafka communique aux clients
      # - kafka:29092 â†’ utilisÃ©e par kafka-ui (mÃªme rÃ©seau Docker)
      # - localhost:9092 â†’ utilisÃ©e par votre code Python/Java/etc.

      # --- Mapping des protocoles de sÃ©curitÃ© ---
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # PLAINTEXT = pas de chiffrement (OK pour dÃ©veloppement local)
      # En production, utilisez SSL/SASL #TODO: passer en donnÃ©es chiffrÃ©es ASAP pour voir la diffÃ©rence

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Nom du listener utilisÃ© pour la coordination KRaft

      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      # Liste des nÅ“uds qui votent pour Ã©lire un controller leader
      # Format: NODE_ID@HOST:PORT
      # Pour un cluster : 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      #
      # ğŸ’¡ EXPLICATION : Ã‰lection du leader
      # Dans un cluster, les brokers votent entre eux pour Ã©lire un "controller leader"
      # qui coordonne le cluster (comme un chef d'Ã©quipe Ã©lu par ses pairs).
      # Ici : 1@kafka:9093 = seul votant (car 1 seul broker)
      # En production avec 3 brokers, tous votent pour Ã©lire le leader.

      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # Listener utilisÃ© pour la communication entre brokers (si cluster multi-nÅ“uds)

      # --- Facteurs de rÃ©plication ---
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Nombre de copies des offsets de consommateurs (1 = pas de rÃ©plication)
      # En production : 3 recommandÃ©

      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      # Minimum In-Sync Replicas pour les transactions (1 = pas de contrainte)

      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # RÃ©plication du log de transactions (1 = pas de rÃ©plication)

      # --- Options pratiques ---
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # CrÃ©e automatiquement un topic quand on y envoie un message
      # Pratique pour dÃ©buter, dÃ©sactiver en production #TODO: Ã  tester pour voir l'impact

      # --- RÃ©tention des messages ---
      KAFKA_LOG_RETENTION_HOURS: 168
      # DurÃ©e de conservation des messages : 168h = 7 jours #TODO: Ã  justifier
      # AprÃ¨s ce dÃ©lai, les messages sont automatiquement supprimÃ©s

      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      # Taille max d'un fichier de log : 1 GB #TODO: Ã  justifier en fonction des donnÃ©es que l'on traite
      # Kafka dÃ©coupe les logs en segments de cette taille

      KAFKA_LOG_DIRS: /var/lib/kafka/data
      # RÃ©pertoire de stockage des messages et mÃ©tadonnÃ©es


    volumes:
      - kafka-data:/var/lib/kafka/data  # Persiste les messages et mÃ©tadonnÃ©es

    networks:
      - dev-cps-network

    # VÃ©rifie que Kafka est vraiment prÃªt (pas juste dÃ©marrÃ©)
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s

  # ===========================
  # SERVICE 3 : Kafka-UI
  # ===========================
  # Interface web pour visualiser et gÃ©rer Kafka facilement
  # FonctionnalitÃ©s :
  # - Voir les topics et leurs messages
  # - CrÃ©er/supprimer des topics
  # - Voir les consommateurs actifs
  # - Monitorer les performances
  #
  # ğŸ’¡ POURQUOI kafka:29092 et pas localhost:9092 ?
  # Kafka-UI tourne dans un conteneur Docker, sur le mÃªme rÃ©seau que Kafka.
  # Il utilise donc le nom de service "kafka" pour communiquer (rÃ©seau interne).
  # Votre code Python/Java sur votre machine utilisera "localhost:9092".
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka                           # Attend que Kafka soit dÃ©marrÃ©
    ports:
      - "8080:8080"                     # Interface web accessible sur http://localhost:8080
    environment:
      KAFKA_CLUSTERS_0_NAME: local      # Nom d'affichage du cluster dans l'interface
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      # Adresse du broker Kafka (utilise kafka:29092 = rÃ©seau Docker interne)
    networks:
      - dev-cps-network

# ===========================
# VOLUMES
# ===========================
# Volumes Docker pour persister les donnÃ©es mÃªme aprÃ¨s "docker compose down"
#
# ğŸ’¡ PERSISTANCE DES DONNÃ‰ES
# Sans volumes : les donnÃ©es sont perdues Ã  chaque "docker compose down"
# Avec volumes : les donnÃ©es persistent sur votre disque dur
#
# Pour Kafka : stocke les messages et mÃ©tadonnÃ©es
# Avec Zookeeper, il fallait aussi un volume pour Zookeeper (zookeeper-data)
# Avec KRaft, seul kafka-data est nÃ©cessaire (tout est dans Kafka)
volumes:
  mongodb-data:                         # DonnÃ©es MongoDB
  kafka-data:                           # Messages et mÃ©tadonnÃ©es Kafka (mode KRaft)

# ===========================
# RÃ‰SEAUX
# ===========================
# RÃ©seau bridge permettant la communication entre conteneurs
#
# ğŸ’¡ RÃ‰SEAU DOCKER
# Tous les services sont sur le mÃªme rÃ©seau "dev-cps-network"
# Cela permet la communication par nom de service :
#   - kafka-ui peut contacter Kafka via "kafka:29092"
#   - Vos applications peuvent contacter MongoDB via "mongodb:27017"
#
# Depuis votre machine (hors Docker), utilisez "localhost" :
#   - Kafka : localhost:9092
#   - MongoDB : localhost:27017
#   - Kafka-UI : localhost:8080
networks:
  dev-cps-network:
    driver: bridge

# ====================================================================
# ğŸš€ DÃ‰MARRAGE RAPIDE
# ====================================================================
#
# 1. Lancer l'environnement :
#    docker compose up -d
#
# 2. VÃ©rifier que tout tourne :
#    docker compose ps
#
# 3. Voir les logs Kafka :
#    docker compose logs -f kafka
#
# 4. AccÃ©der Ã  l'interface web :
#    http://localhost:8080
#
# 5. Se connecter Ã  Kafka depuis votre code :
#    bootstrap_servers = 'localhost:9092'
#
# 6. ArrÃªter l'environnement :
#    docker compose down
#
# 7. ArrÃªter ET supprimer les donnÃ©es :
#    docker compose down -v
#
# ====================================================================
# ğŸ“š POUR EN SAVOIR PLUS
# ====================================================================
#
# Consultez le fichier KAFKA_GUIDE.md pour :
#   - Comprendre les concepts Kafka (Topic, Producer, Consumer, etc.)
#   - Exemples de code Python et JavaScript
#   - Commandes CLI utiles
#   - Cas d'usage et bonnes pratiques
#   - DÃ©pannage et FAQ
#
# ====================================================================