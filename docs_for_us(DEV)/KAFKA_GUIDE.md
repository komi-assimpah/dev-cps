# Guide Kafka pour d√©butants

## Qu'est-ce que Kafka ?

**Apache Kafka** est une plateforme de streaming distribu√©e qui permet de :
- **Publier** et **consommer** des flux de messages en temps r√©el
- **Stocker** ces messages de mani√®re fiable et durable
- **Traiter** les flux de donn√©es au fil de l'eau

### Analogie simple : Kafka = Syst√®me postal num√©rique

Imaginez un bureau de poste ultra-rapide qui :
- Re√ßoit des lettres (messages) de diff√©rents exp√©diteurs (producteurs)
- Les classe dans des bo√Ætes aux lettres nomm√©es (topics)
- Permet √† plusieurs personnes (consommateurs) de lire ces lettres
- Garde les lettres pendant un certain temps (r√©tention)

---

## Concepts cl√©s de Kafka

### 1. **Topic** (Sujet)
Un "canal" ou "cat√©gorie" de messages.

**Exemple :**
- Topic `commandes` : tous les messages de commandes e-commerce
- Topic `logs` : tous les logs applicatifs
- Topic `capteurs-temperature` : donn√©es IoT de capteurs

```
Topic: "commandes"
‚îú‚îÄ‚îÄ Message 1: {"id": 1, "produit": "Laptop", "prix": 899}
‚îú‚îÄ‚îÄ Message 2: {"id": 2, "produit": "Souris", "prix": 25}
‚îî‚îÄ‚îÄ Message 3: {"id": 3, "produit": "Clavier", "prix": 75}
```

### 2. **Producer** (Producteur)
Application qui **envoie** des messages dans un topic.

**Exemple en Python :**
```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# Envoyer un message
producer.send('commandes', {'id': 1, 'produit': 'Laptop', 'prix': 899})
```

### 3. **Consumer** (Consommateur)
Application qui **lit** des messages depuis un topic.

**Exemple en Python :**
```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'commandes',
    bootstrap_servers='localhost:9092',
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

# Lire les messages
for message in consumer:
    print(f"Commande re√ßue: {message.value}")
```

### 4. **Partition**
Un topic est divis√© en **partitions** pour parall√©liser le traitement.

```
Topic "commandes" avec 3 partitions :

Partition 0: [msg1, msg4, msg7, ...]
Partition 1: [msg2, msg5, msg8, ...]
Partition 2: [msg3, msg6, msg9, ...]
```

**Avantages :**
- Plusieurs consommateurs peuvent lire en parall√®le
- Meilleure performance et scalabilit√©

### 5. **Broker**
Le serveur Kafka qui stocke et distribue les messages.

Dans notre configuration, vous avez **1 broker** (pour d√©veloppement).
En production, on utilise plusieurs brokers (3 ou 5) pour la redondance.

### 6. **Consumer Group**
Groupe de consommateurs qui se partagent les partitions d'un topic.

```
Topic avec 3 partitions :

Consumer Group "traitement-commandes" :
‚îú‚îÄ‚îÄ Consumer 1 ‚Üí lit Partition 0
‚îú‚îÄ‚îÄ Consumer 2 ‚Üí lit Partition 1
‚îî‚îÄ‚îÄ Consumer 3 ‚Üí lit Partition 2
```

**Avantages :**
- Charge r√©partie entre plusieurs consommateurs
- Si un consommateur tombe, les autres continuent

---

## Architecture de votre environnement

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Votre Machine (localhost)                ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  MongoDB   ‚îÇ      ‚îÇ   Kafka    ‚îÇ      ‚îÇ Kafka-UI   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  :27017    ‚îÇ      ‚îÇ   :9092    ‚îÇ      ‚îÇ  :8080     ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                             ‚îÇ                    ‚îÇ          ‚îÇ
‚îÇ                             ‚îÇ  kafka:29092       ‚îÇ          ‚îÇ
‚îÇ                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                        (r√©seau Docker interne)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Votre code Python/Java/etc.
      ‚îÇ
      ‚îÇ localhost:9092
      ‚ñº
   Kafka Broker
```

### Ports √† retenir

| Service | Port | Usage |
|---------|------|-------|
| **Kafka** | 9092 | Se connecter depuis votre machine |
| **Kafka** | 9093 | Controller KRaft (interne) |
| **Kafka-UI** | 8080 | Interface web (http://localhost:8080) |
| **MongoDB** | 27017 | Base de donn√©es |

---

## Mode KRaft vs Zookeeper

Votre configuration utilise **KRaft** (architecture moderne).

### Ancienne architecture (Zookeeper)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Zookeeper  ‚îÇ ‚Üê G√®re les m√©tadonn√©es
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Kafka    ‚îÇ ‚Üê Stocke les messages
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Nouvelle architecture (KRaft) - Votre config
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Kafka avec KRaft   ‚îÇ ‚Üê Tout en un !
‚îÇ  (m√©tadonn√©es +     ‚îÇ
‚îÇ   messages)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Avantages de KRaft :**
- Plus simple (1 service au lieu de 2)
- Plus rapide au d√©marrage
- Architecture du futur (Zookeeper sera supprim√© dans Kafka 4.0)

---

## D√©marrage rapide

### 1. Lancer l'environnement
```bash
# D√©marrer tous les services
docker compose up -d

# V√©rifier que tout tourne
docker compose ps

# Voir les logs de Kafka
docker compose logs -f kafka
```

### 2. Acc√©der √† l'interface web
Ouvrez votre navigateur : **http://localhost:8080**

Vous verrez :
- Le cluster "local"
- Les topics existants
- Les brokers actifs

### 3. Cr√©er votre premier topic

**Option A : Via l'interface web**
1. Allez sur http://localhost:8080
2. Cliquez sur "Topics" ‚Üí "Add a Topic"
3. Nom : `test-topic`, Partitions : 3

**Option B : Via la ligne de commande**
```bash
docker exec -it kafka_broker bash

kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --partitions 3 \
  --replication-factor 1
```

### 4. Envoyer des messages

**Via la ligne de commande :**
```bash
docker exec -it kafka_broker bash

kafka-console-producer --bootstrap-server localhost:9092 --topic test-topic
# Tapez vos messages, un par ligne
> Hello Kafka
> Mon premier message
> Ctrl+C pour quitter
```

### 5. Lire les messages

**Via la ligne de commande :**
```bash
docker exec -it kafka_broker bash

kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --from-beginning
```

**Via l'interface web :**
1. Allez sur http://localhost:8080
2. Cliquez sur votre topic
3. Onglet "Messages"

---

## Exemples de code

### Python (avec kafka-python)

**Installation :**
```bash
pip install kafka-python
```

**Producteur :**
```python
from kafka import KafkaProducer
import json
import time

# Cr√©er un producteur
producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# Envoyer des messages
for i in range(10):
    data = {
        'id': i,
        'temperature': 20 + i,
        'timestamp': time.time()
    }
    producer.send('capteurs-temperature', value=data)
    print(f"Message envoy√© : {data}")
    time.sleep(1)

producer.flush()
producer.close()
```

**Consommateur :**
```python
from kafka import KafkaConsumer
import json

# Cr√©er un consommateur
consumer = KafkaConsumer(
    'capteurs-temperature',
    bootstrap_servers='localhost:9092',
    auto_offset_reset='earliest',  # Lire depuis le d√©but
    group_id='mon-groupe',
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

# Lire les messages
print("En attente de messages...")
for message in consumer:
    print(f"Re√ßu : {message.value}")
    print(f"  Partition : {message.partition}")
    print(f"  Offset : {message.offset}")
```

### JavaScript (avec kafkajs)

**Installation :**
```bash
npm install kafkajs
```

**Producteur :**
```javascript
const { Kafka } = require('kafkajs');

const kafka = new Kafka({
  clientId: 'mon-app',
  brokers: ['localhost:9092']
});

const producer = kafka.producer();

async function run() {
  await producer.connect();

  await producer.send({
    topic: 'test-topic',
    messages: [
      { value: 'Hello Kafka from Node.js!' }
    ]
  });

  await producer.disconnect();
}

run();
```

**Consommateur :**
```javascript
const { Kafka } = require('kafkajs');

const kafka = new Kafka({
  clientId: 'mon-app',
  brokers: ['localhost:9092']
});

const consumer = kafka.consumer({ groupId: 'mon-groupe' });

async function run() {
  await consumer.connect();
  await consumer.subscribe({ topic: 'test-topic', fromBeginning: true });

  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      console.log({
        value: message.value.toString(),
        partition,
        offset: message.offset
      });
    }
  });
}

run();
```

---

## Commandes utiles

### Gestion des topics

```bash
# Entrer dans le conteneur Kafka
docker exec -it kafka_broker bash

# Lister tous les topics
kafka-topics --list --bootstrap-server localhost:9092

# Cr√©er un topic
kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic mon-topic \
  --partitions 3 \
  --replication-factor 1

# D√©crire un topic (voir ses partitions, etc.)
kafka-topics --describe --bootstrap-server localhost:9092 --topic mon-topic

# Supprimer un topic
kafka-topics --delete --bootstrap-server localhost:9092 --topic mon-topic
```

### Gestion des messages

```bash
# Produire des messages (console interactive)
kafka-console-producer --bootstrap-server localhost:9092 --topic mon-topic

# Consommer depuis le d√©but
kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic mon-topic \
  --from-beginning

# Consommer avec affichage de la cl√© et des m√©tadonn√©es
kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic mon-topic \
  --from-beginning \
  --property print.key=true \
  --property print.partition=true \
  --property print.offset=true
```

### Gestion des consumer groups

```bash
# Lister les groupes de consommateurs
kafka-consumer-groups --bootstrap-server localhost:9092 --list

# Voir les d√©tails d'un groupe
kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group mon-groupe \
  --describe

# R√©initialiser les offsets (relire depuis le d√©but)
kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group mon-groupe \
  --topic mon-topic \
  --reset-offsets --to-earliest \
  --execute
```

---

## Configuration expliqu√©e

### Variables importantes du docker-compose

| Variable | Valeur | Explication |
|----------|--------|-------------|
| `KAFKA_NODE_ID` | 1 | Identifiant unique du broker |
| `KAFKA_PROCESS_ROLES` | broker,controller | Double r√¥le (stockage + coordination) |
| `KAFKA_AUTO_CREATE_TOPICS_ENABLE` | true | Cr√©e automatiquement les topics |
| `KAFKA_LOG_RETENTION_HOURS` | 168 | Messages gard√©s 7 jours |
| `KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR` | 1 | Pas de r√©plication (1 seul broker) |
| `CLUSTER_ID` | MkU3... | ID unique du cluster (NE PAS CHANGER) |

### Connexion depuis votre code

**Depuis votre machine (Python, Java, Node.js, etc.) :**
```
bootstrap_servers = 'localhost:9092'
```

**Depuis un autre conteneur Docker :**
```
bootstrap_servers = 'kafka:29092'
```

---

## Cas d'usage courants

### 1. Messaging entre microservices
```
Service A ‚Üí [Topic: commandes] ‚Üí Service B
                                ‚Üí Service C (notifications)
                                ‚Üí Service D (facturation)
```

### 2. Collecte de logs
```
Application 1 ‚Üí [Topic: logs] ‚Üí ELK Stack
Application 2 ‚Üó                 (Elasticsearch)
Application 3 ‚Üó
```

### 3. Event Sourcing
```
Actions utilisateur ‚Üí [Topic: events] ‚Üí Base de donn√©es
                                      ‚Üí Analytics
                                      ‚Üí Audit log
```

### 4. IoT et capteurs
```
Capteur 1 ‚Üí [Topic: temperature] ‚Üí Traitement temps r√©el
Capteur 2 ‚Üó                       ‚Üí Stockage MongoDB
Capteur 3 ‚Üó                       ‚Üí Alertes
```

---

## Bonnes pratiques

### Nommage des topics
- ‚úÖ `commandes-creees`, `logs-application`, `capteurs-temperature`
- ‚ùå `topic1`, `test`, `data`

### Partitionnement
- 1 partition = 1 consommateur max
- 3-5 partitions pour d√©buter
- Ajuster selon le volume

### Consumer groups
- Utilisez toujours un `group_id` pour vos consommateurs
- M√™me group_id = charge partag√©e
- Group_id diff√©rents = tous re√ßoivent tous les messages

### Gestion des erreurs
```python
# Toujours g√©rer les exceptions
try:
    producer.send('topic', value=data).get(timeout=10)
except Exception as e:
    print(f"Erreur : {e}")
    # Logger, r√©essayer, etc.
```

---

## D√©pannage

### Kafka ne d√©marre pas
```bash
# Voir les logs d√©taill√©s
docker compose logs kafka

# V√©rifier le healthcheck
docker compose ps
```

### Cannot connect to localhost:9092
```bash
# V√©rifier que Kafka est bien d√©marr√©
docker compose ps

# V√©rifier les ports
netstat -an | grep 9092

# Attendre que Kafka soit vraiment pr√™t (40s au d√©marrage)
docker compose logs -f kafka | grep "started"
```

### Topic not found
```bash
# Si AUTO_CREATE_TOPICS_ENABLE=true, le topic se cr√©e automatiquement
# Sinon, cr√©ez-le manuellement :
kafka-topics --create --bootstrap-server localhost:9092 --topic mon-topic --partitions 3 --replication-factor 1
```

### R√©initialiser compl√®tement
```bash
# Arr√™ter et supprimer TOUTES les donn√©es
docker compose down -v

# Red√©marrer
docker compose up -d
```

---

## Aller plus loin

### Documentation officielle
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Confluent Documentation](https://docs.confluent.io/)

### Biblioth√®ques clientes
- **Python** : kafka-python, confluent-kafka-python
- **Java** : kafka-clients (officiel)
- **Node.js** : kafkajs
- **Go** : confluent-kafka-go
- **.NET** : Confluent.Kafka

### Concepts avanc√©s √† explorer
- Kafka Streams (traitement de flux)
- Kafka Connect (connecteurs vers bases de donn√©es)
- Schema Registry (gestion des sch√©mas Avro/JSON)
- Transactions et exactly-once semantics
- S√©curit√© (SSL/TLS, SASL, ACLs)

---

## Support et ressources

### Commandes Docker Compose

```bash
# D√©marrer
docker compose up -d

# Arr√™ter
docker compose down

# Voir les logs
docker compose logs -f [service]

# Red√©marrer un service
docker compose restart [service]

# Supprimer les donn√©es
docker compose down -v
```

### Kafka-UI
Interface web : **http://localhost:8080**
- Dashboard avec m√©triques
- Gestion des topics
- Visualisation des messages
- Monitoring des consommateurs

### Kafka CLI (ligne de commande)
```bash
# Entrer dans le conteneur
docker exec -it kafka_broker bash

# Toutes les commandes kafka-* sont disponibles
kafka-topics --help
kafka-console-producer --help
kafka-console-consumer --help
```

---

## Questions fr√©quentes

**Q : Quelle diff√©rence entre Kafka et RabbitMQ ?**
- Kafka = streaming de haute performance, persistance, replay
- RabbitMQ = messagerie traditionnelle, accus√©s de r√©ception, routing complexe

**Q : Kafka garde les messages combien de temps ?**
- Dans cette config : 7 jours (168h)
- Configurable avec `KAFKA_LOG_RETENTION_HOURS`

**Q : Combien de consommateurs par partition ?**
- 1 partition = 1 consommateur par consumer group
- Mais plusieurs groups peuvent lire la m√™me partition

**Q : Kafka c'est rapide ?**
- Oui ! Peut g√©rer des millions de messages/seconde
- Latence < 10ms en g√©n√©ral

**Q : Puis-je relire les anciens messages ?**
- Oui ! C'est la force de Kafka
- Les messages persistent pendant la dur√©e de r√©tention

---

**Bonne d√©couverte de Kafka !** üöÄ

Si vous avez des questions, consultez la documentation officielle ou explorez l'interface web √† http://localhost:8080
