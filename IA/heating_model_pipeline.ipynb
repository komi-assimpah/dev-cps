{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b6fbc9",
   "metadata": {},
   "source": [
    "# üî• Mod√®le de Pr√©chauffage\n",
    "\n",
    "Ce notebook centralise tout le pipeline ML pour le mod√®le de pr√©chauffage :\n",
    "1. **Extraction des donn√©es** depuis les fichiers CSV du simulateur\n",
    "2. **Exploration et visualisation** des donn√©es\n",
    "3. **Feature Engineering** avanc√©\n",
    "4. **Entra√Ænement et optimisation** du mod√®le (XGBoost)\n",
    "5. **√âvaluation et export** du mod√®le final\n",
    "\n",
    "**Objectif** : R¬≤ ‚â• 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab221039",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "\n",
    "# ML\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "print(\"Imports charg√©s avec succ√®s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration du pipeline ===\n",
    "CONFIG = {\n",
    "    'data_dir': './data',           # R√©pertoire des donn√©es CSV\n",
    "    'output_csv': 'training_data.csv',  # Fichier de sessions extraites\n",
    "    'model_output': 'heating_model.json',  # Mod√®le final\n",
    "    'test_size': 0.2,               # Proportion test set\n",
    "    'random_state': 42,             # Seed pour reproductibilit√©\n",
    "    'target_r2': 0.80,              # Objectif R¬≤\n",
    "    'session_min_duration': 1,      # Dur√©e min session (minutes)\n",
    "    'session_max_duration': 120,    # Dur√©e max session (minutes)\n",
    "    'min_delta_temp': 0.3,          # Delta temp minimum pour session valide\n",
    "}\n",
    "\n",
    "print(\" Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bbc51c",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Extraction des Donn√©es\n",
    "\n",
    "Chargement des fichiers CSV g√©n√©r√©s par le simulateur et extraction des sessions de chauffage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727163df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_files(data_dir: str) -> List[str]:\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        print(f\"[WARN] Repertoire non trouve: {data_dir}\")\n",
    "        print(\"   Ex√©cutez d'abord:\")\n",
    "        print(\"   cd ../data-generator && python generate.py --mode batch --days 180 --output ../IA/data\")\n",
    "        return []\n",
    "    \n",
    "    csv_files = list(data_path.glob(\"*.csv\"))\n",
    "    return [str(f) for f in csv_files]\n",
    "\n",
    "\n",
    "def load_all_csvs(csv_files: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Charge tous les fichiers CSV en un seul DataFrame.\"\"\"\n",
    "    if not csv_files:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    dfs = []\n",
    "    for f in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            # Extraire apartment_id du nom de fichier (ex: apt_101_2025-12-01.csv)\n",
    "            filename = os.path.basename(f)\n",
    "            parts = filename.replace(\".csv\", \"\").split(\"_\")\n",
    "            if len(parts) >= 2:\n",
    "                apt_id = f\"{parts[0]}_{parts[1]}\".upper()\n",
    "                df[\"apartment_id\"] = apt_id\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lecture {f}: {e}\")\n",
    "    \n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "csv_files = find_csv_files(CONFIG['data_dir'])\n",
    "print(f\" Fichiers CSV trouv√©s: {len(csv_files)}\")\n",
    "\n",
    "raw_data = load_all_csvs(csv_files)\n",
    "print(f\" Enregistrements charg√©s: {len(raw_data):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b36bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es brutes\n",
    "if not raw_data.empty:\n",
    "    print(\"=== Aper√ßu des donn√©es brutes ===\")\n",
    "    display(raw_data.head(10))\n",
    "    \n",
    "    print(f\"\\n=== Types ===\")\n",
    "    print(raw_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_heating_sessions(df: pd.DataFrame, config: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrait les sessions de chauffage du DataFrame.\n",
    "    \n",
    "    Une session = p√©riode o√π heater_on passe de False √† True jusqu'√† temp >= temp_preference.\n",
    "    \"\"\"\n",
    "    sessions = []\n",
    "    \n",
    "    df = df.sort_values([\"apartment_id\", \"room\", \"timestamp\"]).reset_index(drop=True)\n",
    "    \n",
    "    for (apt_id, room), group in df.groupby([\"apartment_id\", \"room\"]):\n",
    "        session_start_idx = None\n",
    "        \n",
    "        for idx, row in group.iterrows():\n",
    "            heater_on = row.get(\"heater_on\", False)\n",
    "            temp = row.get(\"temperature\", 0)\n",
    "            temp_pref = row.get(\"temp_preference\", 21)\n",
    "            \n",
    "            # D√©but d'une session\n",
    "            if heater_on and session_start_idx is None:\n",
    "                session_start_idx = idx\n",
    "            \n",
    "            # Fin de session\n",
    "            elif session_start_idx is not None:\n",
    "                if not heater_on or temp >= temp_pref:\n",
    "                    start_row = group.loc[session_start_idx]\n",
    "                    \n",
    "                    start_time = pd.to_datetime(start_row.get(\"timestamp\"))\n",
    "                    end_time = pd.to_datetime(row.get(\"timestamp\"))\n",
    "                    \n",
    "                    if pd.notna(start_time) and pd.notna(end_time):\n",
    "                        duration_min = (end_time - start_time).total_seconds() / 60\n",
    "                        delta = temp - start_row.get(\"temperature\", 0)\n",
    "                        \n",
    "                        # Filtrer sessions r√©alistes\n",
    "                        if (config['session_min_duration'] < duration_min < config['session_max_duration'] \n",
    "                            and delta >= config['min_delta_temp']):\n",
    "                            sessions.append({\n",
    "                                \"apartment_id\": apt_id,\n",
    "                                \"room\": room,\n",
    "                                \"temp_start\": start_row.get(\"temperature\"),\n",
    "                                \"temp_end\": temp,\n",
    "                                \"temp_preference\": start_row.get(\"temp_preference\", 21),\n",
    "                                \"temp_ext\": start_row.get(\"temp_ext\", 10),\n",
    "                                \"humidity_ext\": start_row.get(\"humidity_ext\", 50),\n",
    "                                \"delta_temp\": delta,\n",
    "                                \"hour\": start_time.hour,\n",
    "                                \"day_of_week\": start_time.dayofweek,\n",
    "                                \"is_weekend\": 1 if start_time.dayofweek >= 5 else 0,\n",
    "                                \"timestamp\": str(start_time),\n",
    "                                \"duration_min\": round(duration_min, 1)\n",
    "                            })\n",
    "                    \n",
    "                    session_start_idx = None\n",
    "    \n",
    "    return pd.DataFrame(sessions)\n",
    "\n",
    "\n",
    "# Extraire les sessions\n",
    "print(\"Extraction des sessions de chauffage...\")\n",
    "sessions_df = extract_heating_sessions(raw_data, CONFIG)\n",
    "print(f\"len : {len(sessions_df)} sessions extraites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les sessions extraites\n",
    "if not sessions_df.empty:\n",
    "    sessions_df.to_csv(CONFIG['output_csv'], index=False)\n",
    "    print(f\"Sessions sauvegard√©es: {CONFIG['output_csv']}\")\n",
    "    \n",
    "    # Statistiques\n",
    "    print(f\"\\n=== Statistiques des sessions ===\")\n",
    "    print(f\"   Appartements: {sessions_df['apartment_id'].nunique()}\")\n",
    "    print(f\"   Pi√®ces: {sessions_df['room'].nunique()}\")\n",
    "    print(f\"   Dur√©e moyenne: {sessions_df['duration_min'].mean():.1f} min\")\n",
    "    print(f\"   Dur√©e m√©diane: {sessions_df['duration_min'].median():.1f} min\")\n",
    "    print(f\"   Delta temp moyen: {sessions_df['delta_temp'].mean():.2f}¬∞C\")\n",
    "    \n",
    "    display(sessions_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711becc",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Exploration et Visualisation\n",
    "\n",
    "Analyse exploratoire pour comprendre les patterns dans les donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des temp√©ratures \n",
    "if not raw_data.empty:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    axes[0].hist(raw_data['temperature'], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(raw_data['temperature'].mean(), color='red', linestyle='--', label='Moyenne')\n",
    "    axes[0].set_title('Temp√©rature int√©rieure')\n",
    "    axes[0].set_xlabel('Temp√©rature (¬∞C)')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].hist(raw_data['temp_ext'], bins=30, edgecolor='black', color='blue', alpha=0.7)\n",
    "    axes[1].axvline(raw_data['temp_ext'].mean(), color='red', linestyle='--', label='Moyenne')\n",
    "    axes[1].set_title('Temp√©rature ext√©rieure')\n",
    "    axes[1].set_xlabel('Temp√©rature (¬∞C)')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    axes[2].hist(raw_data['temp_preference'], bins=20, edgecolor='black', color='green', alpha=0.7)\n",
    "    axes[2].set_title('Temp√©rature cible')\n",
    "    axes[2].set_xlabel('Temp√©rature (¬∞C)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=== Statistiques des temp√©ratures ===\")\n",
    "    print(f\"Temp int√©rieure: min={raw_data['temperature'].min():.1f}, max={raw_data['temperature'].max():.1f}, mean={raw_data['temperature'].mean():.1f}\")\n",
    "    print(f\"Temp ext√©rieure: min={raw_data['temp_ext'].min():.1f}, max={raw_data['temp_ext'].max():.1f}, mean={raw_data['temp_ext'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des sessions de chauffage\n",
    "if not sessions_df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Dur√©e de chauffage\n",
    "    axes[0, 0].hist(sessions_df['duration_min'], bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "    axes[0, 0].axvline(sessions_df['duration_min'].mean(), color='red', linestyle='--', \n",
    "                       label=f\"Moyenne: {sessions_df['duration_min'].mean():.1f} min\")\n",
    "    axes[0, 0].set_title('Distribution des dur√©es de chauffage')\n",
    "    axes[0, 0].set_xlabel('Dur√©e (minutes)')\n",
    "    axes[0, 0].set_ylabel('Fr√©quence')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Delta temp√©rature\n",
    "    axes[0, 1].hist(sessions_df['delta_temp'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0, 1].axvline(sessions_df['delta_temp'].mean(), color='red', linestyle='--',\n",
    "                       label=f\"Moyenne: {sessions_df['delta_temp'].mean():.2f}¬∞C\")\n",
    "    axes[0, 1].set_title('Distribution des deltas de temp√©rature')\n",
    "    axes[0, 1].set_xlabel('Delta (¬∞C)')\n",
    "    axes[0, 1].set_ylabel('Fr√©quence')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Scatter delta vs duration\n",
    "    axes[1, 0].scatter(sessions_df['delta_temp'], sessions_df['duration_min'], alpha=0.5, c='purple')\n",
    "    axes[1, 0].set_xlabel('Delta temp√©rature (¬∞C)')\n",
    "    axes[1, 0].set_ylabel('Dur√©e (minutes)')\n",
    "    axes[1, 0].set_title('Delta vs Dur√©e de chauffage')\n",
    "    corr = sessions_df['delta_temp'].corr(sessions_df['duration_min'])\n",
    "    axes[1, 0].annotate(f'Corr√©lation: {corr:.3f}', xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                        fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat'))\n",
    "    \n",
    "    # Sessions par heure\n",
    "    sessions_df['hour'].value_counts().sort_index().plot(kind='bar', ax=axes[1, 1], color='teal', alpha=0.7)\n",
    "    axes[1, 1].set_title('Sessions de chauffage par heure')\n",
    "    axes[1, 1].set_xlabel('Heure')\n",
    "    axes[1, 1].set_ylabel('Nombre de sessions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70706737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corr√©lation\n",
    "if not sessions_df.empty:\n",
    "    numeric_cols = sessions_df.select_dtypes(include=[np.number]).columns\n",
    "    corr_matrix = sessions_df[numeric_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "                square=True)\n",
    "    plt.title('Matrice de corr√©lation des features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Corr√©lations avec la variable cible\n",
    "    print(\"\\n=== Corr√©lations avec duration_min ===\")\n",
    "    target_corr = corr_matrix['duration_min'].sort_values(ascending=False)\n",
    "    print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b59875",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Engineering\n",
    "\n",
    "Cr√©ation de features avanc√©es pour am√©liorer la performance du mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(path: str, quantile_low: float = 0.05, quantile_high: float = 0.95) -> pd.DataFrame:\n",
    "    \"\"\"Charge et nettoie le dataset.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # Filtrer les outliers\n",
    "    q1 = df['duration_min'].quantile(quantile_low)\n",
    "    q3 = df['duration_min'].quantile(quantile_high)\n",
    "    df = df[(df['duration_min'] >= q1) & (df['duration_min'] <= q3)]\n",
    "    \n",
    "    print(f\"   Avant nettoyage: {initial_count}\")\n",
    "    print(f\"   Apr√®s nettoyage: {len(df)} ({100*len(df)/initial_count:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_features(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, List[str]]:\n",
    "    \"\"\"Feature engineering avanc√©.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Encodage cat√©goriel\n",
    "    le_room = LabelEncoder()\n",
    "    le_apt = LabelEncoder()\n",
    "    df[\"room_encoded\"] = le_room.fit_transform(df[\"room\"])\n",
    "    df[\"apt_encoded\"] = le_apt.fit_transform(df[\"apartment_id\"])\n",
    "    \n",
    "    # Features temporelles binaires\n",
    "    df[\"morning\"] = ((df[\"hour\"] >= 6) & (df[\"hour\"] < 10)).astype(int)\n",
    "    df[\"day\"] = ((df[\"hour\"] >= 10) & (df[\"hour\"] < 17)).astype(int)\n",
    "    df[\"evening\"] = ((df[\"hour\"] >= 17) & (df[\"hour\"] < 22)).astype(int)\n",
    "    \n",
    "    # Features d√©riv√©es\n",
    "    df[\"delta_squared\"] = df[\"delta_temp\"] ** 2\n",
    "    df[\"temp_diff_ext\"] = df[\"temp_start\"] - df[\"temp_ext\"]\n",
    "    df[\"heating_difficulty\"] = df[\"delta_temp\"] * (20 - df[\"temp_ext\"]) / 10\n",
    "    df[\"target_gap\"] = df[\"temp_preference\"] - df[\"temp_start\"]\n",
    "    \n",
    "    # Features d'interaction\n",
    "    df[\"delta_x_hour\"] = df[\"delta_temp\"] * df[\"hour\"]\n",
    "    df[\"ext_x_hour\"] = df[\"temp_ext\"] * df[\"hour\"]\n",
    "    \n",
    "    feature_columns = [\n",
    "        \"delta_temp\", \"delta_squared\", \"temp_ext\", \"temp_start\",\n",
    "        \"temp_preference\", \"humidity_ext\", \"hour\",\n",
    "        \"room_encoded\", \"apt_encoded\",\n",
    "        \"morning\", \"day\", \"evening\",\n",
    "        \"temp_diff_ext\", \"heating_difficulty\", \"target_gap\",\n",
    "        \"delta_x_hour\", \"ext_x_hour\"\n",
    "    ]\n",
    "    \n",
    "    available = [c for c in feature_columns if c in df.columns]\n",
    "    \n",
    "    X = df[available].astype(float)\n",
    "    y = df[\"duration_min\"]\n",
    "    \n",
    "    return X, y, available\n",
    "\n",
    "\n",
    "print(\"Chargement et nettoyage des donn√©es...\")\n",
    "df_clean = load_and_clean_data(CONFIG['output_csv'])\n",
    "\n",
    "X, y, features = prepare_features(df_clean)\n",
    "print(f\"   {len(features)} features cr√©√©es\")\n",
    "print(f\"   Features: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aaec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=CONFIG['test_size'], \n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "\n",
    "print(f\" Split du dataset:\")\n",
    "print(f\"   Train: {len(X_train)} √©chantillons\")\n",
    "print(f\"   Test:  {len(X_test)} √©chantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867b4b4",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Entra√Ænement du Mod√®le\n",
    "\n",
    "Entra√Ænement avec XGBoost et optimisation des hyperparam√®tres via GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Comparaison de Mod√®les ===\n",
    "print(\" Comparaison de plusieurs algorithmes...\")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=CONFIG['random_state']),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=CONFIG['random_state']),\n",
    "    \"XGBoost\": xgb.XGBRegressor(n_estimators=400, max_depth=6, learning_rate=0.02, random_state=CONFIG['random_state'])\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"   Entra√Ænement {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"R2\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"R2\", ascending=False)\n",
    "print(\"\\n R√©sultats :\")\n",
    "display(results_df)\n",
    "\n",
    "# On garde XGBoost comme r√©f√©rence pour la suite (compatible GridSearch sp√©cifique)\n",
    "baseline_model = models[\"XGBoost\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV pour optimisation\n",
    "print(\" GridSearchCV pour optimisation des hyperparam√®tres...\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'max_depth': [5, 6, 7, 8],\n",
    "    'learning_rate': [0.01, 0.02, 0.03],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    xgb.XGBRegressor(random_state=CONFIG['random_state']),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nMeilleurs hyperparam√®tres trouv√©s:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\n   Meilleur R¬≤ (CV): {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Entra√Ænement du mod√®le final optimis√©...\")\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "final_model = xgb.XGBRegressor(\n",
    "    **best_params,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=CONFIG['random_state']\n",
    ")\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluation finale\n",
    "y_pred_final = final_model.predict(X_test)\n",
    "r2_final = r2_score(y_test, y_pred_final)\n",
    "mae_final = mean_absolute_error(y_test, y_pred_final)\n",
    "rmse_final = np.sqrt(mean_squared_error(y_test, y_pred_final))\n",
    "\n",
    "print(f\"\\nR√©sultats Mod√®le Final:\")\n",
    "print(f\"   R¬≤ Score: {r2_final:.3f} ({r2_final*100:.1f}%)\")\n",
    "print(f\"   MAE:      {mae_final:.2f} min\")\n",
    "print(f\"   RMSE:     {rmse_final:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation sur le mod√®le final\n",
    "print(\"Cross-validation (5-fold)...\")\n",
    "\n",
    "cv_scores = cross_val_score(final_model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "print(f\"   Scores par fold: {[f'{s:.3f}' for s in cv_scores]}\")\n",
    "print(f\"   Moyenne:  {cv_scores.mean():.3f}\")\n",
    "print(f\"   √âcart-type: {cv_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf896615",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. √âvaluation et Analyse du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed04a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Importance des Features (XGBoost)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Top 5 Features ===\")\n",
    "print(feature_importance.tail(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fee687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des pr√©dictions vs r√©alit√©\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_pred_final, alpha=0.5, c='steelblue')\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Pr√©diction parfaite')\n",
    "axes[0].set_xlabel('Dur√©e r√©elle (min)')\n",
    "axes[0].set_ylabel('Dur√©e pr√©dite (min)')\n",
    "axes[0].set_title(f'Pr√©dictions vs R√©alit√© (R¬≤={r2_final:.3f})')\n",
    "axes[0].legend()\n",
    "\n",
    "# Distribution des erreurs\n",
    "errors = y_pred_final - y_test\n",
    "axes[1].hist(errors, bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[1].axvline(0, color='red', linestyle='--', label='Erreur nulle')\n",
    "axes[1].axvline(errors.mean(), color='blue', linestyle='--', label=f'Moyenne: {errors.mean():.2f}')\n",
    "axes[1].set_xlabel('Erreur (min)')\n",
    "axes[1].set_ylabel('Fr√©quence')\n",
    "axes[1].set_title('Distribution des erreurs')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Statistiques des erreurs ===\")\n",
    "print(f\"   Erreur moyenne: {errors.mean():.2f} min\")\n",
    "print(f\"   Erreur std:     {errors.std():.2f} min\")\n",
    "print(f\"   Erreur max:     {abs(errors).max():.2f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7fdfc",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Export du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04727211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le meilleur mod√®le et sauvegarder\n",
    "\n",
    "# R√©cup√©rer le meilleur score de la phase de comparaison\n",
    "# results_df est tri√© par R2 descendant\n",
    "best_comparison_r2 = results_df.iloc[0][\"R2\"]\n",
    "best_comparison_name = results_df.iloc[0][\"Model\"]\n",
    "\n",
    "print(f\"Meilleur mod√®le comparaison: {best_comparison_name} (R2={best_comparison_r2:.3f})\")\n",
    "print(f\"Mod√®le optimis√© final: XGBoost Optimis√© (R2={r2_final:.3f})\")\n",
    "\n",
    "if r2_final >= best_comparison_r2:\n",
    "    best_model = final_model\n",
    "    best_r2 = r2_final\n",
    "    model_name = \"XGBoost Optimis√©\"\n",
    "else:\n",
    "    # On r√©cup√®re le meilleur mod√®le de la liste 'models'\n",
    "    # Attention: requires 'models' dict to be available\n",
    "    best_model = models[best_comparison_name]\n",
    "    best_r2 = best_comparison_r2\n",
    "    model_name = best_comparison_name\n",
    "\n",
    "# Sauvegarder\n",
    "# Note: save_model is specific to XGBoost. If the best model is NOT XGBoost, we might need joblib.\n",
    "# For simplicity in this specific pipeline context where we want a JSON output for the system,\n",
    "# we might prefer XGBoost. But let's handle the general case or stick to XGBoost.\n",
    "# The user wants the best model.\n",
    "\n",
    "if \"XGBoost\" in model_name:\n",
    "    best_model.save_model(CONFIG['model_output'])\n",
    "    print(f\"\\nüíæ Mod√®le XGBoost sauvegard√©: {CONFIG['model_output']}\")\n",
    "else:\n",
    "    import joblib\n",
    "    pkl_filename = CONFIG['model_output'].replace('.json', '.pkl')\n",
    "    joblib.dump(best_model, pkl_filename)\n",
    "    print(f\"\\nüíæ Mod√®le sklearn sauvegard√©: {pkl_filename}\")\n",
    "    print(f\"‚ö†Ô∏è Attention: Le format JSON est attendu par le simulateur, mais le meilleur mod√®le est {model_name}.\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"üèÜ MOD√àLE FINAL CHOISI: {model_name}\")\n",
    "print(f\"   R¬≤ Score: {best_r2:.3f} ({best_r2*100:.1f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if best_r2 >= CONFIG['target_r2']:\n",
    "    print(f\"\\n‚úÖ OBJECTIF ATTEINT! R¬≤ ‚â• {CONFIG['target_r2']*100:.0f}%\")\n",
    "else:\n",
    "    print(f\"\\n R¬≤ = {best_r2:.1%} - Objectif {CONFIG['target_r2']*100:.0f}% non atteint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719aa519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de chargement du mod√®le\n",
    "print(\"üîÑ Test de chargement du mod√®le...\")\n",
    "\n",
    "loaded_model = xgb.XGBRegressor()\n",
    "loaded_model.load_model(CONFIG['model_output'])\n",
    "\n",
    "# V√©rification\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "r2_loaded = r2_score(y_test, y_pred_loaded)\n",
    "\n",
    "print(f\"   R¬≤ apr√®s rechargement: {r2_loaded:.3f}\")\n",
    "print(f\"   ‚úÖ Mod√®le valid√©!\" if np.isclose(r2_loaded, best_r2) else \"   ‚ùå Erreur de chargement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e616c",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Exemple d'utilisation du mod√®le\n",
    "\n",
    "Comment utiliser le mod√®le pour faire une pr√©diction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_heating_duration(model, delta_temp: float, temp_ext: float, temp_start: float,\n",
    "                             temp_preference: float = 21, humidity_ext: float = 50,\n",
    "                             hour: int = 7, room_encoded: int = 0, apt_encoded: int = 0) -> float:\n",
    "    \"\"\"\n",
    "    Pr√©dit la dur√©e de chauffage n√©cessaire.\n",
    "    \n",
    "    Args:\n",
    "        delta_temp: √âcart de temp√©rature √† combler (¬∞C)\n",
    "        temp_ext: Temp√©rature ext√©rieure (¬∞C)\n",
    "        temp_start: Temp√©rature de d√©part (¬∞C)\n",
    "        temp_preference: Temp√©rature cible (¬∞C)\n",
    "        humidity_ext: Humidit√© ext√©rieure (%)\n",
    "        hour: Heure de la journ√©e (0-23)\n",
    "        room_encoded: ID encod√© de la pi√®ce\n",
    "        apt_encoded: ID encod√© de l'appartement\n",
    "    \n",
    "    Returns:\n",
    "        Dur√©e estim√©e de chauffage (minutes)\n",
    "    \"\"\"\n",
    "    # Construire les features\n",
    "    morning = 1 if 6 <= hour < 10 else 0\n",
    "    day = 1 if 10 <= hour < 17 else 0\n",
    "    evening = 1 if 17 <= hour < 22 else 0\n",
    "    \n",
    "    features = np.array([[\n",
    "        delta_temp,\n",
    "        delta_temp ** 2,  # delta_squared\n",
    "        temp_ext,\n",
    "        temp_start,\n",
    "        temp_preference,\n",
    "        humidity_ext,\n",
    "        hour,\n",
    "        room_encoded,\n",
    "        apt_encoded,\n",
    "        morning,\n",
    "        day,\n",
    "        evening,\n",
    "        temp_start - temp_ext,  # temp_diff_ext\n",
    "        delta_temp * (20 - temp_ext) / 10,  # heating_difficulty\n",
    "        temp_preference - temp_start,  # target_gap\n",
    "        delta_temp * hour,  # delta_x_hour\n",
    "        temp_ext * hour,  # ext_x_hour\n",
    "    ]])\n",
    "    \n",
    "    return model.predict(features)[0]\n",
    "\n",
    "\n",
    "# Exemples de pr√©diction\n",
    "print(\"=== Exemples de pr√©diction ===\")\n",
    "\n",
    "scenarios = [\n",
    "    {\"delta_temp\": 2.0, \"temp_ext\": 5, \"temp_start\": 18, \"hour\": 7, \"desc\": \"Matin froid, +2¬∞C\"},\n",
    "    {\"delta_temp\": 3.0, \"temp_ext\": 0, \"temp_start\": 17, \"hour\": 6, \"desc\": \"Matin tr√®s froid, +3¬∞C\"},\n",
    "    {\"delta_temp\": 1.5, \"temp_ext\": 10, \"temp_start\": 19, \"hour\": 18, \"desc\": \"Soir doux, +1.5¬∞C\"},\n",
    "    {\"delta_temp\": 4.0, \"temp_ext\": -5, \"temp_start\": 16, \"hour\": 7, \"desc\": \"Matin glacial, +4¬∞C\"},\n",
    "]\n",
    "\n",
    "for s in scenarios:\n",
    "    duration = predict_heating_duration(\n",
    "        loaded_model,\n",
    "        delta_temp=s[\"delta_temp\"],\n",
    "        temp_ext=s[\"temp_ext\"],\n",
    "        temp_start=s[\"temp_start\"],\n",
    "        hour=s[\"hour\"]\n",
    "    )\n",
    "    print(f\"\\n{s['desc']}:\")\n",
    "    print(f\"   Dur√©e estim√©e: {duration:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8f887",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù R√©sum√© et Conclusions\n",
    "\n",
    "### Pipeline complet\n",
    "1. **Extraction** : Chargement des CSV et extraction des sessions de chauffage\n",
    "2. **Exploration** : Visualisation des distributions et corr√©lations\n",
    "3. **Feature Engineering** : Cr√©ation de 17 features (temporelles, d√©riv√©es, interactions)\n",
    "4. **Entra√Ænement** : XGBoost avec GridSearchCV pour optimisation\n",
    "5. **√âvaluation** : R¬≤, MAE, RMSE, cross-validation\n",
    "6. **Export** : Sauvegarde du mod√®le au format JSON\n",
    "\n",
    "### Prochaines √©tapes\n",
    "- G√©n√©rer plus de donn√©es avec des sc√©narios vari√©s\n",
    "- Tester d'autres algorithmes (LightGBM, CatBoost)\n",
    "- Int√©grer le mod√®le dans le service de pr√©chauffage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
